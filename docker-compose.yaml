# version: '3.8' # 移除此行，因为它已过时

services:
  # Go 应用程序: post_search - 本地运行，此处仅作占位或移除
  # app:
  #   build: # 本地运行，不需要build
  #     context: .
  #     dockerfile: Dockerfile
  #   ports: # 本地运行时，Go程序直接监听8080，不需要Docker端口映射
  #     - "8080:8080"
  #   depends_on: # 依赖关系依然重要，但启动顺序由你手动控制
  #     kafka:
  #       condition: service_healthy
  #     elasticsearch:
  #       condition: service_healthy
  #   environment: # 本地运行时，通过本地配置文件或环境变量
  #     CONFIG_PATH: /app/config/config.development.yaml
  #   volumes: # 本地运行时，直接读取本地文件系统
  #     - ./post_search/config:/app/config
  #   restart: unless-stopped
  #   healthcheck: # 本地运行，不需要容器健康检查
  #     test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080/_health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 30s

  # Kafka (KRaft 模式, 无 Zookeeper)
  kafka:
    image: confluentinc/cp-kafka:7.6.1 # 这个仍然需要能从镜像源拉取
    container_name: kafka_post_search_kraft_local
    ports:
      - "9092:9092" # 暴露给宿主机，你的Go应用将连接 localhost:9092
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:9093' # 容器内部通信用kafka:9093
      KAFKA_LISTENERS: 'PLAINTEXT_HOST://:9092,PLAINTEXT_INTERNAL://:19092,CONTROLLER://:9093' # 修改此行
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT_HOST://localhost:9092,PLAINTEXT_INTERNAL://kafka:19092' # 修改此行
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'PLAINTEXT_HOST:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT' # 新增此行
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT_INTERNAL' # 修改此行
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      CLUSTER_ID: '1IOGvJTQRHekq5NzkDNl-w' # 使用您之前生成的 ID
      # KAFKA_CREATE_TOPICS: "PostAudit:1:1,PostDelete:1:1,search_service_dlq:1:1" # 主题可以由你的应用首次连接时自动创建（如果Kafka配置允许），或者你进入容器手动创建
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list > /dev/null 2>&1 || exit 1"] # 健康检查也用localhost
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # Elasticsearch
  elasticsearch:
    build: ./elasticsearch_custom # <--- 修改为这一行
#    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.4 # 暂时注释掉，从我们本地配置的dockerfile中拉取，原因是为了自己配置中文分词器
    container_name: post_search-elasticsearch-1
    ports:
      - "9200:9200" # 暴露给宿主机，你的Go应用将连接 localhost:9200
      - "9300:9300" # ES内部通信端口，通常不需要宿主机访问，但有时需要
    environment:
      discovery.type: single-node
      xpack.security.enabled: false # 保持false，简化本地开发连接
      ES_JAVA_OPTS: "-Xms512m -Xmx512m"
      # 如果需要在容器外部访问，确保 network.host 设置为允许外部连接，
      # 但对于单节点且通过ports映射，通常默认的 localhost/127.0.0.1 绑定在容器内，通过端口映射实现外部访问
      # 如有连接问题，可尝试添加下面这行，但这会使ES监听所有网络接口，需注意安全
      # network.host: 0.0.0.0
    volumes:
      - es_data:/usr/share/elasticsearch/data
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    healthcheck:
      test: ["CMD-SHELL", "curl -s --fail http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=5s || exit 1"] # 健康检查也用localhost
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

#  kafka的webUI可视化容器
  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop_ui # 给它一个容器名
    ports:
      - "9000:9000" # 将 Kafdrop UI 映射到宿主机的 9000 端口
    environment:
      # 注意这里：我们使用 Kafka 的内部监听器和宣告地址
      KAFKA_BROKERCONNECT: "kafka:19092"
      # JVM_OPTS: "-Xms32m -Xmx64m" # （可选）如果需要，可以限制 Kafdrop 的内存
    depends_on:
      kafka: # 确保 Kafka 启动后再启动 Kafdrop
        condition: service_healthy # 等待 Kafka 健康检查通过
    restart: unless-stopped

# ES的可视化工具
  kibana:
    image: docker.elastic.co/kibana/kibana:8.13.4 # 使用与您 Elasticsearch 版本匹配的 Kibana 版本
    container_name: post_search-kibana-1 # 给它一个容器名
    ports:
      - "5601:5601" # Kibana UI 默认在 5601 端口
    environment:
      # 告诉 Kibana 你的 Elasticsearch 服务在哪里
      # "elasticsearch" 是您 docker-compose.yml 中 Elasticsearch 服务的名称
      ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
    depends_on:
      elasticsearch: # 确保 Elasticsearch 启动后再启动 Kibana
        condition: service_healthy # 等待 Elasticsearch 健康检查通过
    restart: unless-stopped



volumes:
  kafka_data:
  es_data:


